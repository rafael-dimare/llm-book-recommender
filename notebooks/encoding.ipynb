{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3edf81-be00-4841-8625-cada51985a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25026075-a89e-448e-9b55-de7726ce71fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ghost logging to avoid splitting warnings\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.getLogger(\"langchain_text_splitters.base\").setLevel(logging.ERROR)\n",
    "old_log_record_factory = logging.getLogRecordFactory()\n",
    "\n",
    "def new_log_record_factory(*args, **kwargs):\n",
    "    record = old_log_record_factory(*args, **kwargs)\n",
    "    if record.getMessage().startswith(\"Created a chunk of size\"):\n",
    "        return None\n",
    "    return record\n",
    "\n",
    "logging.setLogRecordFactory(new_log_record_factory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c2e76e-e56d-4056-9c5d-585385bc98ea",
   "metadata": {},
   "source": [
    "# Creating a Embeddings-vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c4b5d3-9233-4cf4-8856-763e24294c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data table and only write documents content\n",
    "\n",
    "books = pd.read_csv(\"../data/books_cleaned.csv\")\n",
    "books['tagged_description'].to_csv(\"data/tagged_description.txt\", sep=\"\\n\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f043ef-80a4-4393-85cc-86d4952d5a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load documents, configure text splitter, and perform splitting\n",
    "\n",
    "raw_documents = TextLoader(\"../data/tagged_description.txt\").load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1, chunk_overlap=0, separator=\"\\n\")\n",
    "documents = text_splitter.split_documents(raw_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b9cae4-87ee-4c17-9951-e66de0013a49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e86b97b-671e-459d-b8ad-1f9bad826ec5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize embeddings model\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ec7560-ebd6-43bf-9fab-04020c020b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract texts\n",
    "texts = [doc.page_content.strip(\"\\\"\") for doc in documents]\n",
    "\n",
    "#Process embeddings in batches\n",
    "batch_size = 16\n",
    "embeddings = []\n",
    "\n",
    "for i in tqdm(range(0, len(texts), batch_size), desc=\"Embedding batches\"):\n",
    "    batch = texts[i:i + batch_size]\n",
    "    batch_embeddings = embedding_model.embed_documents(batch)\n",
    "    embeddings.extend(batch_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a3bdef-af76-4e86-91cf-c992d189008e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PERSIST_DIR = '../data/db_books_embeddings'\n",
    "\n",
    "db_books = Chroma(\n",
    "    embedding_function=embedding_model, # Used for queries\n",
    "    persist_directory = PERSIST_DIR     # Optional: set a folder if you want it saved\n",
    ")\n",
    "\n",
    "# Add the data manually\n",
    "db_books._collection.add(\n",
    "    ids=[text[:13] for text in texts],\n",
    "    embeddings=embeddings,\n",
    "    documents=[text[15:] for text in texts],\n",
    "    metadatas=[doc.metadata for doc in documents]\n",
    ")\n",
    "\n",
    "print(f\"Successfully created and saved {len(embeddings)} documents to '{PERSIST_DIR}'\")\n",
    "print(f\"Current document count: {db_books._collection.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3aad13-e0e8-49aa-b17b-f17f33cc2551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading test\n",
    "\n",
    "db_books_loaded = Chroma(\n",
    "    embedding_function=embedding_model,\n",
    "    persist_directory=PERSIST_DIR\n",
    ")\n",
    "\n",
    "count = db_books_loaded._collection.count()\n",
    "print(f\"Successfully loaded database with {count} documents from '{PERSIST_DIR}'.\")\n",
    "\n",
    "# Example query to show it works\n",
    "results = db_books_loaded.similarity_search(\"Classic literature\", k=1)\n",
    "print(f\"Query Result: {results[0].page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad871777-e136-4b3b-a8cd-c47d466f39b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"A book to teach children about nature\"\n",
    "docs = db_books.similarity_search(query, k=5)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b5d577-13ce-49fd-829e-1b49538d72bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "query = \"A book for teaching kids about nature\"\n",
    "docs = db_books.similarity_search(query, k=5)\n",
    "ids = [int(doc.id) for doc in docs]\n",
    "books.query(\"isbn13.isin(@ids)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9620159-3f03-4743-87a2-f01b411c821c",
   "metadata": {},
   "source": [
    "# Zero-shot categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f39bed6-4157-4840-9e7f-826644d4d2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping of top-12 categories\n",
    "category_mapping = {\n",
    "    'Fiction' : \"Fiction\",\n",
    "    'Juvenile Fiction': \"Children's Fiction\",\n",
    "    'Biography & Autobiography': \"Nonfiction\",\n",
    "    'History': \"Nonfiction\",\n",
    "    'Literary Criticism': \"Nonfiction\",\n",
    "    'Philosophy': \"Nonfiction\",\n",
    "    'Religion': \"Nonfiction\",\n",
    "    'Comics & Graphic Novels': \"Fiction\",\n",
    "    'Drama': \"Fiction\",\n",
    "    'Juvenile Nonfiction': \"Children's Nonfiction\",\n",
    "    'Science': \"Nonfiction\",\n",
    "    'Poetry': \"Fiction\"\n",
    "}\n",
    "\n",
    "books[\"simple_categories\"] = books[\"categories\"].map(category_mapping)\n",
    "\n",
    "#Proportions of null values in category fields\n",
    "books[['categories', 'simple_categories']].isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c060e449-b235-4cad-b110-c52569f9c68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fiction_categories = ['Fiction', 'Nonfiction']\n",
    "\n",
    "pipe = pipeline(\"zero-shot-classification\",\n",
    "                model=\"facebook/bart-large-mnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f65fdc-8950-4114-9716-f2ce3b09fdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = books['description'].iloc[50]\n",
    "\n",
    "pipe(sequence, fiction_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ed0fbf-0083-474d-8780-052c12d2336b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions(sequence: str, categories: list[str]) -> str:\n",
    "    predictions = pipe(sequence, categories)\n",
    "    max_index = np.argmax(predictions[\"scores\"])\n",
    "    max_label = predictions[\"labels\"][max_index]\n",
    "    return max_label\n",
    "\n",
    "f = lambda sequence: generate_predictions(sequence, fiction_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d1d503-8431-4cb7-bc75-20f94421ead2",
   "metadata": {},
   "source": [
    "Let us now predict the category for the missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f381fb18-9555-43ac-94cf-2283bf807b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_categories = books[\"description\"].progress_apply(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094a45b4-5c45-4b98-8ce5-d7c343a6ef0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_categories.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46cbe62-db79-4401-ab61-a7931b113699",
   "metadata": {},
   "outputs": [],
   "source": [
    "books['categories'].isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c04353-32f0-4293-8765-4b0ecb48f00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "books['predicted_categories'] = pred_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafb8172-4a96-4949-b5a0-98cf88941750",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = \"Fiction\"\n",
    "acc = books.query(\"simple_categories == @cat\").eval(\"simple_categories == predicted_categories\").mean()\n",
    "print(f\"Category prediction accuracy for {cat}: {acc:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d530f8fa-1b99-4474-8de3-10f20faf4dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = \"Nonfiction\"\n",
    "acc = books.query(\"simple_categories == @cat\").eval(\"simple_categories == predicted_categories\").mean()\n",
    "print(f\"Category prediction accuracy for {cat}: {acc:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1c3b02-ef71-4cfb-8a28-46c2b8922d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "books.to_csv('../data/books_pred_categories.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629845a0-fc3d-4bde-b4a8-bc926653d8f6",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52265d26-a0fe-4a0f-8a05-ff9fb700ce07",
   "metadata": {},
   "source": [
    "The goal is to classify the dominant emotion in the book among 7 categories: anger, disgust, fear, joy, neutral, sadness, and surprise. Instead of using zero-shot classification, we will use a fine-tuned model on this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f643401-6652-4850-a9f0-b88535d76024",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from transformers import pipeline\n",
    "classifier = pipeline(\"text-classification\",\n",
    "                      model=\"j-hartmann/emotion-english-distilroberta-base\",\n",
    "                      top_k=None)\n",
    "classifier(\"I love this!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cc8b1f-3528-4533-b1b0-d5d62a8f5301",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = books['description'][0]\n",
    "print(desc)\n",
    "classifier(desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c222b380-b261-4426-aa65-0478225b6121",
   "metadata": {},
   "source": [
    "Descriptions have a mix of different feelinds. Let's divide the description into different sentences and pass them to the classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00772829-00d5-4ce7-aa1b-3f0d3ed6da30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentences = [sentence.strip() for sentence in books['description'][0].split(\".\") if len(sentence.strip())>0]\n",
    "predictions = classifier(sentences)\n",
    "\n",
    "for sentence, pred in zip(sentences, predictions):\n",
    "    print(sentence)\n",
    "    display(pred)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757d4bcf-5d3f-46fb-8c63-be316c26e52a",
   "metadata": {},
   "source": [
    "For each book, let's have a separate column, one for each sentiment class. Let's then take the highest probability from accross the whole description for that particular sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36f8ce8-43f2-4d7b-92a0-f0bd540dab20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_max_emotion_scores(predictions):\n",
    "    all_scores = [(d['label'], d['score']) for sublist in predictions for d in sublist]\n",
    "    result = pd.DataFrame(all_scores, columns=['emotion','score']).groupby(\"emotion\").max()['score']\n",
    "    return result\n",
    "\n",
    "calculate_max_emotion_scores(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7389159c-d9ba-4a75-9eec-9c4963ba6f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = books['description'][1]\n",
    "print(desc)\n",
    "\n",
    "sentences = [s for sentence in desc.split(\".\") if len(s := sentence.strip())>0]\n",
    "predictions = classifier(sentences)\n",
    "calculate_max_emotion_scores(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bcb7c8-d6ac-41b5-9e2e-029bdd2b4bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_emotion_scores(desc):\n",
    "    sentences = [s for sentence in desc.split(\".\") if len(s := sentence.strip())>0]\n",
    "    predictions = classifier(sentences)\n",
    "    scores = calculate_max_emotion_scores(predictions)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6727572e-321e-4f87-955f-7d9b919f320f",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_scores = books.set_index(\"isbn13\")['description'].progress_apply(compute_emotion_scores).reset_index()\n",
    "books_with_sentiment_analysis = books.merge(emotion_scores, on='isbn13', validate='1:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44c1042-7961-4688-ba3a-0ede528ce6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_with_sentiment_analysis.to_csv('../data/books_for_dashboard.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
